{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelo Baseline: TFIDF + Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4566 1142\n"
     ]
    }
   ],
   "source": [
    "# alldf = pd.read_csv(\"../data/prep/clean_ruddit.csv\")\n",
    "train = pd.read_csv(\"../data/prep/train_ruddit.csv\")\n",
    "test = pd.read_csv(\"../data/prep/test_ruddit.csv\")\n",
    "print(train.shape[0], test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = list(train[\"clean_text\"].str.split().values), list(train[\"score\"].values)\n",
    "X_test, y_test = list(test[\"clean_text\"].str.split().values), list(test[\"score\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=lambda doc: doc,\n",
    "    preprocessor=lambda doc: doc,\n",
    "    token_pattern=None\n",
    ")\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10208"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.vocabulary_) # vocabulary length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4566, 10208)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n"
     ]
    }
   ],
   "source": [
    "for k, v in zip(tfidf.vocabulary_.keys(), tfidf.vocabulary_.values()):\n",
    "    print(k) if v == 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.38027714, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.92412427, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tfidf.transform([[\"!\"], [\"hello\", \"!\", \"fuck\"], [\"people\", \"!\", \"!\"]]).todense()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    # \"solver\": [\"auto\", \"cholesky\", \"lsqr\", \"saga\"],\n",
    "    \"alpha\": np.logspace(-5, 5, 11)\n",
    "}\n",
    "baseline_model = Ridge(fit_intercept=True, random_state=2)\n",
    "# baseline_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "\n",
      "Baseline training time: 0:00:02.076992\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "baseline_search = GridSearchCV(estimator=baseline_model, param_grid=param_grid,\n",
    "                                       scoring=\"neg_mean_squared_error\", cv=5, n_jobs=-1, verbose=4)\n",
    "baseline_search.fit(X_train, y_train)\n",
    "# print(baseline_random_search)\n",
    "print(\"\\nBaseline training time: {}\".format(timedelta(seconds=time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorer: make_scorer(mean_squared_error, greater_is_better=False)\n",
      "Mejor configuraci贸n:\n",
      "Ridge(random_state=2)\n",
      "MSE del mejor modelo tras la validaci贸n cruzada: -0.053\n"
     ]
    }
   ],
   "source": [
    "print(\"Scorer: {}\".format(baseline_search.scorer_))\n",
    "print(\"Mejor configuraci贸n:\")\n",
    "print(baseline_search.best_estimator_)\n",
    "print(\"MSE del mejor modelo tras la validaci贸n cruzada: {}\".format(\n",
    "    round(baseline_search.best_score_, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = baseline_search.cv_results_\n",
    "cv_results_df = pd.DataFrame(cv_results)[[\"params\", \"mean_test_score\", \"std_test_score\"]]\n",
    "cv_results_df[[\"mean_test_score\", \"std_test_score\"]] = cv_results_df[\n",
    "    [\"mean_test_score\", \"std_test_score\"]].apply(lambda x: round(x, 4))\n",
    "cv_results_df[\"alpha\"] = cv_results_df[\"params\"].apply(lambda params_dict: params_dict[\"alpha\"])\n",
    "# cv_results_df[\"solver\"] = cv_results_df[\"params\"].apply(lambda params_dict: params_dict[\"solver\"])\n",
    "cv_results_df.drop(columns=\"params\", inplace=True)\n",
    "cv_results_df[\"mean_test_score\"] =  - cv_results_df[\"mean_test_score\"] * 100\n",
    "cv_results_df[\"std_test_score\"] =  cv_results_df[\"std_test_score\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_mse</th>\n",
       "      <th>std_mse</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.05</td>\n",
       "      <td>0.65</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.91</td>\n",
       "      <td>0.74</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.91</td>\n",
       "      <td>0.74</td>\n",
       "      <td>100000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.67</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.11</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_mse  std_mse         alpha\n",
       "0       5.30     0.29       1.00000\n",
       "1       6.24     0.29       0.10000\n",
       "2       7.13     0.39      10.00000\n",
       "3       9.30     0.29       0.01000\n",
       "4      10.05     0.65     100.00000\n",
       "5      10.82     0.73    1000.00000\n",
       "6      10.91     0.74   10000.00000\n",
       "7      10.91     0.74  100000.00000\n",
       "8      13.67     1.05       0.00100\n",
       "9      16.94     2.36       0.00010\n",
       "10     20.11     4.06       0.00001"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking de candidatos\n",
    "cv_results_df.sort_values(by=\"mean_test_score\", ascending=True).reset_index(drop=True).rename(\n",
    "    columns={\"mean_test_score\": \"mean_mse\", \"std_test_score\": \"std_mse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 5.2%\n"
     ]
    }
   ],
   "source": [
    "# Hold-out validation\n",
    "selected_model = baseline_search.best_estimator_\n",
    "y_pred = selected_model.predict(X_test)\n",
    "mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "print(\"MSE:\", str(round(mse * 100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcular R ajustado\n",
    "# TODO: Calcular MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
